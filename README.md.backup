# virtual-interpreter
AI solution to translate your voice messages into other languages - in your own voice!

## Requirements:
This script is tested with the following configuration:
 - OS: Ubuntu 22.04 LTS
 - Kernel: 5.15
 - NVIDIA driver version: 535
 - CUDA version: 12.2
 - GPUs: 2 x RTX 3080

## Used models:
 - multilingual speech recognition: [whisper](https://github.com/openai/whisper). From OpenAI but open source and runnable locally; https://github.com/openai/whisper
 - translation: [argostranslate](https://github.com/argosopentech/argos-translate)
 - text-to-speech conversion and voice cloning: [coqui-TTS](https://github.com/coqui-ai/TTS). Keep in mind that the license only allows to use this model for free for non-commercial use, otherwise, a commercial license is required.

## Installation:
First, you need to install Anaconda (miniconda, to reduce the download size ):
```
sudo apt update && sudo apt upgrade -y
sudo apt install curl git    
curl -sL "https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh" > "Miniconda3.sh"
bash ./Miniconda.sh
```
Log out and log back in. Then run the following:
```
conda env create  --yes --file requirements.yml
```

## Running:
Activate the conda environment, then run the script and follow the instructions:
```
conda activate whisper
python interpreter.py
```

##
